{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MNIST dataset from Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element represents the pixel of a greyscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.images[0]\n",
    "data.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show first 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels=list(zip(data.images,data.target))\n",
    "plt.figure(figsize=(7,7))\n",
    "for index,(image,label) in enumerate(images_and_labels[:10]):\n",
    "    plt.subplot(2,5,index+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image,cmap=plt.cm.gray_r,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=len(data.images)\n",
    "X=data.images.reshape((n_samples,-1))\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1797\n",
      "Shape of input matrix X: (1797, 64)\n",
      "Shape of target vector y: (1797,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: \"+ str(n_samples))\n",
    "print(\"Shape of input matrix X: \"+str(X.shape))\n",
    "print(\"Shape of target vector y: \"+str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set to training, validadation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output model will have 10 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.T\n",
    "X_test=X_test.T\n",
    "y_train=y_train.reshape(y_train.shape[0],1)\n",
    "y_test=y_test.reshape(y_test.shape[0],1)\n",
    "y_train=y_train.T\n",
    "y_test=y_test.T\n",
    "\n",
    "Y_train_=np.zeros((10,y_train.shape[1]))\n",
    "for i in range(y_train.shape[1]):\n",
    "    Y_train_[y_train[0,i],i]=1\n",
    "    \n",
    "    \n",
    "Y_test_=np.zeros((10,y_test.shape[1]))\n",
    "for i in range(y_test.shape[1]):\n",
    "    Y_test_[y_test[0,i],i]=1\n",
    "\n",
    "n_x=X_train.shape[0]\n",
    "n_h=10\n",
    "n_y=Y_train_.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) \n",
    "    for l in range(1, L):\n",
    "        parameters['w' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(x, w, b):\n",
    "    Z = np.dot(w,x)+b\n",
    "    cache = (x, w, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions and their derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def ReLU_(Z):\n",
    "    return Z*(Z>0)\n",
    "\n",
    "def dReLU_(Z):\n",
    "    return 1. *(Z>0)\n",
    "\n",
    "def dsigmoid_(Z):\n",
    "    return sigmoid_(Z)*(1-sigmoid_(Z))\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return sigmoid_(Z),Z\n",
    "\n",
    "def ReLU(Z):\n",
    "    return ReLU_(Z),Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation:\n",
    "If the type of activation is sigmoid, it performs sigmoid activation function else performs ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(x_prev,w,b,activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(x_prev,w,b)\n",
    "        x, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    elif activation == \"ReLU\":\n",
    "        Z, linear_cache = linear_forward(x_prev,w,b)\n",
    "        x, activation_cache = ReLU(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return x, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation for all layers in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    x = X\n",
    "    L = len(parameters) // 2   \n",
    "    for l in range(1, L):\n",
    "        x_prev = x \n",
    "        x, cache = linear_activation_forward(x_prev,parameters['w'+str(l)],parameters['b'+str(l)],\"ReLU\")\n",
    "        caches.append(cache)\n",
    "    xL, cache = linear_activation_forward(x,parameters['w'+str(L)],parameters['b'+str(L)],\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    return xL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function for the output AL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(xL, Y):\n",
    "    m=Y.shape[1]\n",
    "    cost = -(1/m)*np.sum((Y*np.log(xL)+(1-Y)*np.log(1-xL)))\n",
    "    cost=np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    x_prev, w, b = cache\n",
    "    m = x_prev.shape[1]\n",
    "    dw = (1/m)*np.dot(dZ,x_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dx_prev = np.dot(w.T,dZ)\n",
    "    \n",
    "    return dx_prev, dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions for  ReLU layer and for sigmoid layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_backward(dx,activation_cache):\n",
    "    return dx* dReLU_(activation_cache)\n",
    "\n",
    "def sigmoid_backward(dx,activation_cache):\n",
    "    return dx* dsigmoid_(activation_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall backward propagation function for one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dx, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == \"ReLU\":\n",
    "        dZ = ReLU_backward(dx,activation_cache)\n",
    "        dx_prev, dw, db = linear_backward(dZ,linear_cache)\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dx,activation_cache)\n",
    "        dx_prev, dw, db = linear_backward(dZ,linear_cache)\n",
    "    return dx_prev,dw,db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Backward propagation for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(xL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = xL.shape[1]\n",
    "    \n",
    "    dxL = - (np.divide(Y, xL) - np.divide(1 - Y, 1 - xL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dx\" + str(L-1)], grads[\"dw\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dxL,current_cache,\"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dx_prev_temp, dw_temp, db_temp = linear_activation_backward(grads[\"dx\"+str(l+1)],current_cache,\"ReLU\")\n",
    "        grads[\"dx\" + str(l)] = dx_prev_temp\n",
    "        grads[\"dw\" + str(l + 1)] = dw_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the weights using computed derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 \n",
    "    for l in range(L):\n",
    "        parameters[\"w\" + str(l+1)] = parameters[\"w\" + str(l+1)]-(learning_rate)*grads[\"dw\"+str(l+1)] \n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-(learning_rate)*grads[\"db\"+str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims=[n_x,60,10,10]\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.005, num_iterations = 100000, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = [] \n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        xL, caches = L_model_forward(X, parameters)\n",
    "        cost = compute_cost(xL, Y)\n",
    "        grads = L_model_backward(xL, Y, caches)\n",
    "        parameters = update_weights(parameters, grads, learning_rate)\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after %i iterations: %f\" %(i, cost))\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            costs.append(cost)\n",
    "        if cost < 0.1:\n",
    "            break\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 iterations: 6.931433\n",
      "Cost after 1000 iterations: 3.774829\n",
      "Cost after 2000 iterations: 3.262610\n",
      "Cost after 3000 iterations: 3.249175\n",
      "Cost after 4000 iterations: 3.248149\n",
      "Cost after 5000 iterations: 3.245551\n",
      "Cost after 6000 iterations: 3.234484\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9b607d6f4d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-b5def90f2fda>\u001b[0m in \u001b[0;36mL_layer_model\u001b[0;34m(X, Y, layers_dims, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mxL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_model_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_model_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-c3750baa904a>\u001b[0m in \u001b[0;36mL_model_backward\u001b[0;34m(xL, Y, caches)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcurrent_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdx_prev_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_activation_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dx\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ReLU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dx\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx_prev_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dw\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdw_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-8b76de29f69a>\u001b[0m in \u001b[0;36mlinear_activation_backward\u001b[0;34m(dx, cache, activation)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ReLU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLU_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdx_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinear_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-61d65b20a602>\u001b[0m in \u001b[0;36mlinear_backward\u001b[0;34m(dZ, cache)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdx_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = L_layer_model(X_train, Y_train_, layers_dims, num_iterations = 100000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_L_layer(X,parameters):\n",
    "    xL,caches=L_model_forward(X,parameters)\n",
    "    prediction=np.argmax(xL,axis=0)\n",
    "    return prediction.reshape(1,prediction.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_L = predict_L_layer(X_train, parameters)\n",
    "print(\"Training Accuracy : \"+ str(np.sum(predictions_train_L==y_train)/y_train.shape[1] * 100)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_L=predict_L_layer(X_test,parameters)\n",
    "print(\"Testing Accuracy : \"+ str(np.sum(predictions_test_L==y_test)/y_test.shape[1] * 100)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pylab as pl\n",
    "\n",
    "for j in range(7):\n",
    "    i=random.randint(0,n_samples)\n",
    "    pl.gray()\n",
    "    pl.matshow(data.images[i])\n",
    "    pl.show()\n",
    "    img=data.images[i].reshape((64,1)).T\n",
    "    img = sc.transform(img)\n",
    "    img=img.T\n",
    "    predicted_digit=predict_L_layer(img,parameters)\n",
    "    print('Predicted digit is : '+str(predicted_digit))\n",
    "    print('True digit is: '+ str(y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/machine-learning-algorithms-from-scratch/digit-recognition-from-0-9-using-deep-neural-network-from-scratch-8e6bcf1dbd3\n",
    "https://github.com/pavankalyan1997/Machine-learning-without-any-libraries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
